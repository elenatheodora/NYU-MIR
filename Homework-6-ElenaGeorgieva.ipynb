{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\n",
    "**Total Points: 5**\n",
    "\n",
    "**Instructions:**\n",
    "1. Complete parts 1 through 5, filling in code or responses where marked with `# YOUR CODE HERE` or `# YOUR ANALYSIS HERE`.\n",
    "2. The libraries you need, in the order you need them, have already been coded. Do not import additional libraries or move import commands.\n",
    "3. When finished, run the full notebook by selecting <b>Kernel > Restart & Run All</b>. </li>\n",
    "4. Submit this completed notebook file to <b>NYU Classes</b>. </li>**(Important: Only submit your .ipynb file! Do not submit the entire dataset.)**\n",
    "\n",
    "In this assignment you will test different ML techniques to classify solo instruments. This assignment uses a large dataset (9+ GB) which you will download separately: *Medley-solos-DB*:\n",
    "\n",
    "<blockquote>\n",
    "V. Lostanlen, C.E. Cella. Deep convolutional networks on the pitch spiral for musical instrument recognition. Proceedings of the International Society for Music Information Retrieval Conference (ISMIR), 2016.\n",
    "</blockquote>\n",
    "\n",
    "**Grading:** Each part is worth 1 point.\n",
    "\n",
    "**Important Note**: The way you implement the code in your work for each assignment is entirely up to you. There are often many ways to solve a particular problem, so use whatever method works for you. The only requirement is that you follow the instructions, which may prohibit or require certain libraries or commands. Refer to https://scikit-learn.org/ for implementation instructions and tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from librosa import feature\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prologue: Download the Dataset and Metadata\n",
    "\n",
    "The data you will need is a folder containing wav audio files, and a separate .csv file with metadata. You can download both from the following page:\n",
    "\n",
    "https://zenodo.org/record/3464194#.X4G_oi2z3kJ\n",
    "\n",
    "Place both the folder and csv file into the same directory as your `Homework-6.ipynb` file, such that the folder stucture is as follows:\n",
    "\n",
    "`\n",
    " .\n",
    " <--   Homework-6.ipynb\n",
    " <--   Medley-solos-DB_metadata.csv\n",
    " <--   Medley-solos-DB\n",
    " |     <--   *.wav files\n",
    "`\n",
    "\n",
    "The audio files contain recordings from 8 different instuments which have already been labeled and separated into training, validation, and test sets. Each audio file is the same length, and there are many example files from each instrument.\n",
    "\n",
    "Each audio file has a unique id number associated with it ('uuid4'). This id is important when extracting the audio data and making sure that the file has the correct label, as referenced in the csv file. The following two cells will load and display the metadata into a `Medley_Data` DataFrame. No changes should be made to the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load amd Check the csv file\n",
    "\n",
    "Medley_Data = pd.read_csv(\"Medley-solos-DB_metadata.csv\")\n",
    "#Medley_Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function: `get_file_name_and_label()` and `get_ids()`\n",
    "\n",
    "The following helper functions have been provided for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5841 tracks in the training set\n",
      "There are 3494 tracks in the validation set\n",
      "There are 12236 tracks in the test set\n"
     ]
    }
   ],
   "source": [
    "def get_file_name_and_label(uuid, path='Medley-solos-DB/', dataset=Medley_Data):\n",
    "    \"\"\" Returns full file name and path from a uuid\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    uuid: str \n",
    "        the unique id (uuid4) for the audio file\n",
    "    \n",
    "    path: str\n",
    "        relative path to audio files\n",
    "        \n",
    "    dataset: pandas.DataFrame\n",
    "        the DataFrame to consult (Medley_Data)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    filename: str\n",
    "        relative path and filename\n",
    "    label: int\n",
    "        the label associated with that filename\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    rd = dataset.loc[ (dataset['uuid4'] == uuid) ]\n",
    "    file = path + 'Medley-solos-DB' + '_' + str(rd.values[0,0]) + '-'  + str(rd.values[0,2]) + '_' + rd.values[0,4] + '.wav'\n",
    "    label = rd.values[0,2]\n",
    "    return(file, label)\n",
    "                       \n",
    "def get_ids(subset, path = 'Medley-solos-DB/', dataset = Medley_Data):\n",
    "\n",
    "    \"\"\" Get a np array of all uuids or a subset of files in the dataset\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "        subset: str\n",
    "            one of 'training', 'validation, 'test', or 'all'\n",
    "            \n",
    "        path: str\n",
    "            relative path to the audio files\n",
    "            \n",
    "        dataset: pd.DataFrame\n",
    "            The Medley-solos-DB dataframe to search\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "        filename: np.array\n",
    "            Medley-solos-DB file name (or 0 if not found)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    file_array = np.array([])\n",
    "    rd = dataset.loc[ (dataset['subset'] == subset) ]\n",
    "    if len(rd.index) < 1:\n",
    "        file_array = np.array([0])\n",
    "    else:\n",
    "        k = 0\n",
    "        for i in range(len(rd.index)):\n",
    "            file_array = np.append(file_array,rd.iloc[k,4])\n",
    "            k += 1\n",
    "    return(file_array)\n",
    "\n",
    "\n",
    "# Divides up file names into training, validation, and test sets\n",
    "tracks_train =  get_ids('training')\n",
    "tracks_validate = get_ids('validation')\n",
    "tracks_test = get_ids('test')\n",
    "\n",
    "print(\"There are {} tracks in the training set\".format(len(tracks_train)))\n",
    "print(\"There are {} tracks in the validation set\".format(len(tracks_validate)))\n",
    "print(\"There are {} tracks in the test set\".format(len(tracks_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1a: Compute Features\n",
    "\n",
    "Create a function `compute_features()` such that the input is one audio file and the output is a single feature vector. This function should do the following:\n",
    "1. Load audio into a sample array.\n",
    "2. Compute the MFCCs of the input audio, and remove the first (0th) coeficient.\n",
    "3. Compute the summary statistics of the MFCCs over time:\n",
    "    1. Find the mean and standard deviation for each feature (2 values for each feature)\n",
    "    2. stack these statistics into single 1-d vector of size (2*(n_mfccs-1))\n",
    "4. Return the 1-d vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(audiofile, n_fft=2048, hop_length=512, n_mels=128, n_mfcc=20):\n",
    "    \"\"\"Compute features for an audio file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    audiofile : str\n",
    "        name of audio file (with relative directory path)\n",
    "    n_fft : int\n",
    "        Number of points for computing the fft\n",
    "    hop_length : int\n",
    "        Number of samples to advance between frames\n",
    "    n_mels : int\n",
    "        Number of mel frequency bands to use\n",
    "    n_mfcc : int\n",
    "        Number of mfccs to compute\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    features: np.array (1, 2* (n_mfcc - 1))\n",
    "        feature vector\n",
    "\n",
    "    \"\"\"\n",
    "    # 1 Load audio into a sample array.\n",
    "    y, fs = librosa.load(audiofile)\n",
    "    \n",
    "    # 2 Compute the MFCCs of the input audio, and remove the first (0th) coeficient.\n",
    "    mfccs = librosa.feature.mfcc(y, fs) \n",
    "    mfccs = mfccs[1:len(mfccs)] # 19 by len\n",
    "\n",
    "    # 3 Compute the summary statistics of the MFCCs over time:\n",
    "    # 3a Find the mean and standard deviation for each feature (2 values for each feature)\n",
    "    # 3b stack these statistics into single 1-d vector of size (2*(n_mfccs-1))\n",
    "    means = mfccs.mean(axis = 1) # for mean of each row\n",
    "    stds = mfccs.std(axis = 1) # for std of each row\n",
    "\n",
    "    #features = np.concatenate(means,stds)\n",
    "    features = np.append(means, stds)\n",
    "    \n",
    "    # 4 Return the 1-d vector. \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Part 1b: Create Feature Set\n",
    "\n",
    "Create a function `create_feature_set()` where the input is an array of audio files and output is a normalized feature set and an accompanying vector of class labels. This function should:\n",
    "1. Iterate through all audio files in a list of uuids. The training, test, and validation lists have been created for you. For each uuid:\n",
    "    1. Use `get_file_name_and_label()` to retrieve the audio file name and associated label\n",
    "    2. Use `compute_features()` to get the 1-d vector for that audio file.\n",
    "    3. Append the feature vector and label to their respective arrays, and continue to the next file.\n",
    "2. When finished, output 2 numpy arrays: the feature matrix (n_samples, 2*(mfccs-1)) and the label (n_samples,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_set(id_list):\n",
    "    \"\"\"Create feature set from list of input ids.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    id_list: np.array\n",
    "        array of uuid (track_test, track_validate, track_train)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    features: np.array (n_samples, n_features)\n",
    "        The standard deviation of the features\n",
    "    labels: np.array (n_samples)\n",
    "        corresponding label for each feature\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # 1 Iterate through all audio files in a list of uuids. The training, test, and validation lists have been created for you. For each uuid:\n",
    "        \n",
    "    # 2 Use get_file_name_and_label() to retrieve the audio file name and associated label\n",
    "    # Use compute_features() to get the 1-d vector for that audio file.\n",
    "    # Append the feature vector and label to their respective arrays, and continue to the next file.\n",
    "    nTracks = len(id_list)\n",
    "    \n",
    "    features = np.zeros((nTracks, 38)) \n",
    "    labels = np.zeros(nTracks)\n",
    "    counter = 0\n",
    "    for id1 in id_list:\n",
    "        id1_filename, id1_label = get_file_name_and_label(id1)\n",
    "        id1_features = compute_features(id1_filename)\n",
    "        features[counter,:] = id1_features\n",
    "        labels[counter] = id1_label\n",
    "        counter +=1\n",
    "    \n",
    "    # 3 When finished, output 2 numpy arrays: the feature matrix (n_samples, 2*(mfccs-1)) and the label (n_samples,)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Get Mean and Standard Deviation\n",
    "\n",
    "Create a function `get_stats()` which gets the mean and standard deviation for each feature in the input matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(features):\n",
    "    \"\"\" Get mean and standard deviation of each feature in a set\n",
    " \n",
    "    Parameters\n",
    "    ---------\n",
    "    \n",
    "    features: np.array (n_samples, n_features)\n",
    "        feature set\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "     \n",
    "    mean: np.array (n_features)\n",
    "        mean of input feature set\n",
    "    std_dev: np.array (n_features)\n",
    "        standard deviation of input feature set\n",
    "\n",
    "    \"\"\"\n",
    "    # gets the mean and standard deviation for each feature in the input matrix.\n",
    "    means = features.mean(axis = 0) # for mean of each col\n",
    "    stds = features.std(axis = 0) # for std of each col\n",
    "    return means, stds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Everything Ready\n",
    "\n",
    "The code in the following cell has been done for you. When all is well, run the code to compute features and training labels for the 3 data sets in Medley-solos-DB.\n",
    "\n",
    "**Hint:** Since you are processing many GB of data, this code will take a while to run. To make sure everything works as expected, you may want to test on small subset of the data, like `tracks_train[0:500]`. Although the output won't be valid for the ML experiments, you can verify that the shapes of the output matrices and vectors are correct. \n",
    "\n",
    "**Another Hint:** This code will save feature sets and labels to your computer so it won't need to be re-computed if not necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set: (12236, 38)\n",
      "Training Set: (5841, 38)\n",
      "Validation Set: (3494, 38)\n"
     ]
    }
   ],
   "source": [
    "# THIS CODE IS PROVIDED FOR YOU\n",
    "\n",
    "# Change this to True if you want to load prevously-computed features\n",
    "load_saved_tests = True ######## originally false\n",
    "\n",
    "if not load_saved_tests:\n",
    "    test_set, test_labels = create_feature_set(tracks_test)\n",
    "    print(\"Test Set: \" + str(test_set.shape))\n",
    "    train_set, train_labels = create_feature_set(tracks_train)\n",
    "    print(\"Training Set: \" + str(train_set.shape))\n",
    "    validate_set, validate_labels = create_feature_set(tracks_validate)\n",
    "    print(\"Validation Set: \" + str(validate_set.shape))\n",
    "    np.savetxt('test_set.csv', test_set, delimiter=',')\n",
    "    np.savetxt('test_labels.csv', test_labels, delimiter=',')\n",
    "    np.savetxt('train_set.csv', train_set, delimiter=',')\n",
    "    np.savetxt('train_labels.csv', train_labels, delimiter=',')\n",
    "    np.savetxt('validate_set.csv', validate_set, delimiter=',')\n",
    "    np.savetxt('validate_labels.csv', validate_labels, delimiter=',')\n",
    "else:\n",
    "    test_set = np.loadtxt('test_set.csv',delimiter=',')\n",
    "    test_labels = np.loadtxt('test_labels.csv',delimiter=',')\n",
    "    train_set = np.loadtxt('train_set.csv',delimiter=',')\n",
    "    train_labels = np.loadtxt('train_labels.csv',delimiter=',')\n",
    "    validate_set = np.loadtxt('validate_set.csv',delimiter=',')\n",
    "    validate_labels = np.loadtxt('validate_labels.csv',delimiter=',')\n",
    "    print(\"Test Set: \" + str(test_set.shape))\n",
    "    print(\"Training Set: \" + str(train_set.shape))\n",
    "    print(\"Validation Set: \" + str(validate_set.shape))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2b: Normalize Feature Sets\n",
    "\n",
    "Using `get_stats()` find the mean and standard deviations for the training set. Then use those statistics to make all 3 data sets have a mean of 0 and standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using get_stats() find the mean and standard deviations for the training set. \n",
    "training_means, training_stds = get_stats(train_set)\n",
    "testing_means, testing_stds = get_stats(test_set)\n",
    "validation_means, validation_stds = get_stats(validate_set)\n",
    "\n",
    "# Then use those statistics to make all 3 data sets have a mean of 0 and standard deviation of 1.\n",
    "new_training = (train_set - training_means)/training_stds\n",
    "new_testing = (test_set - testing_means)/testing_stds\n",
    "new_validation= (validate_set - validation_means)/validation_stds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: k-Nearest Neighbor\n",
    "\n",
    "Using the data from part 1, run a kNN classification experienment:\n",
    "\n",
    "- Use `sklearn` entirely\n",
    "- Run tests on the validation set with k = 1, 5, 20, and 50\n",
    "- When you decide on the best settings (best f-measure), run the experiment on the test set and output the f-measure and a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Now, we test on the Testing set: \n",
      "\n",
      "confusion matrix:\n",
      " [[ 152   27    9   34  280   19    4  207]\n",
      " [   0  814    1    0   71    8    0   61]\n",
      " [   0    5  696    0   57  118    0  266]\n",
      " [  75   85   92  402 1293   17   83 1120]\n",
      " [   0   31    2    1 2558    0    0   17]\n",
      " [   0   89    6    0  111   25   11   83]\n",
      " [  15    1    1    5   33   17  222  112]\n",
      " [  14  146    9   31  604    4    2 2090]]\n",
      "f1 score 0.5687316116377902\n"
     ]
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1) #defaul nneighbors i 5\n",
    "\n",
    "#3 \"Fit\" the training data to the model (this basically means \"train the model\").\n",
    "thefit = knn.fit(new_training, train_labels)\n",
    "\n",
    "#4 Use cross_val_scores() on the classifier, setting cv=10 and output the scores.\n",
    "#f1 = cross_val_score(knn, new_training, train_labels, cv=10, scoring='precision')\n",
    "\n",
    "#5 Get predictions using `predict() with the test data.\n",
    "final_predictions = knn.predict(new_validation)\n",
    "\n",
    "#6 Print the confusion matrix using the true vs. predicted labels.\n",
    "c = confusion_matrix(validate_labels, final_predictions)\n",
    "# print(\"confusion matrix:\\n\" , c) # uncomment to see the confusion matrix while trying different k values\n",
    "# print(\"f1 score\", f1_score(validate_labels, final_predictions, average=\"micro\")) # uncomment to see the f1 scores while trying different k values\n",
    "print(\"\\n\", \"Now, we test on the Testing set:\", \"\\n\")\n",
    "test_predictions = knn.predict(new_testing)\n",
    "c = confusion_matrix(test_labels, test_predictions)\n",
    "print(\"confusion matrix:\\n\" , c) # Final confusion matrix w test set\n",
    "print(\"f1 score\", f1_score(test_labels, test_predictions, average=\"micro\")) # fomal f1 scores w test set\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Multi-Layered Perceptron (Neural Network)\n",
    "\n",
    "Using the same data, run the same test using the MLP classifier.\n",
    "\n",
    "- Use `sklearn` entirely\n",
    "- Run tests on the validation set to experiment with the number of iterations and size and number of hidden layers.\n",
    "- Initially, try setting `max_iter=100` and `hidden_layer_sizes=(5,2)` (meaning 2 hidden layers of sizes 5 and 2.\n",
    "- When you decide on the best settings (best f-measure), run the experiment on the test set and output the f-measure and a confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCOMPLETE\n",
    "# mlp = neural_network.MLPClassifier()\n",
    "# mlp.fit(new_training, train_labels) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Analysis\n",
    "\n",
    "For each machine learning method:\n",
    "\n",
    "1. Predict the labels for the test set using hyperparameters from the validation set\n",
    "2. Compute & print the f-measures\n",
    "3. Compute and print the confusion matrix\n",
    "\n",
    "For each method, report on the following:\n",
    "\n",
    "4. Which instrument class has the best & worst performance?\n",
    "5. For the worst source, what other sources are commonly confused? Why?\n",
    "6. Listen to the audio for examples the classifier got wrong. What do they have in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN: RESULTS FROM VARYING K\n",
    "# k = 5 I got f1 = 0.6963365769891242\n",
    "# k = 1 I got f1 = 0.6983400114481969\n",
    "# k = 20 I got f1 = 0.6734401831711505\n",
    "# k = 50 I got f1 = 0.6296508299942759 \n",
    "# These were with 'micro' averaging. The highest f1 value is for k = 1, but the k=5 is very close! \n",
    "# Uncomment The F-measure and confusion matrix is printed at the bottom of part 3, the k value can be changed to see the other confusion matrices.\n",
    "\n",
    "# PART 2 ---\n",
    "# The f-score with the test set is 0.5687316116377902\n",
    "# PART 3 ---\n",
    "# The confusion matrix is printed above at the bottom of Part 3\n",
    "# PART 4  ---\n",
    "# The best performance: piano\n",
    "# The worst performance: flute\n",
    "# PART 5 ---\n",
    "# Flute is often confused with paino violin. In fact, flute is predicted to be a piano or a violin much more often than it is precicted to be a flute. \n",
    "# PART 6 ---\n",
    "# I listened to clips of the flute and violin. They play in the same frequency range and have a similar mild vibrato. I can see why the classifier confuses flute and violin.\n",
    "# The piano also often plays in a high range. I think this dataset could benefit from more varied and representative piano samples, as I didn't hear many samples of large chords, or more on the low-frequency part of the piano. \n",
    "# Of course, I can't listen to all of the piano samples but this is the impression I got from the subset I did listen to. \n",
    "# It seems like this KNN classifier tends to classify things as piano more than anything else. This is some kind of bias that would be important to investigate if I was working on this as a research project.\n",
    "\n",
    "# MULTI-LAYER PERCEPTRON\n",
    "# I did not get to the MLP part of the assignment \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`# YOUR ANALYSIS HERE`"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
